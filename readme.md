# LangChainGo Ollama Local LLM Chatting

## Overview

This application demonstrates using LangChainGo with Ollama to generate text for Go-backed LLM tools. It showcases local AI model interaction, streaming generation, and context-based content generation.

## Features

- Local AI Model generation with ollama.
- Streaming text output and content generation.
- Flexxible system and user message configuration.
  
## Error Handling

The application includes basic error handling:

- Check For Ollama initialization errors.
- Manages content generation errors.
